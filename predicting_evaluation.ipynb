{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "df=pd.read_csv('chessData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[10000:20000]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval=eval.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval=df['Evaluation']\n",
    "eval=eval.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.decode_FEN import FEN_to_arr\n",
    "positions=[]\n",
    "extras=[]\n",
    "for i in df['FEN']:\n",
    "    pos,extr=FEN_to_arr(i)\n",
    "    positions.append(pos)\n",
    "    extras.append(extr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(eval)):\n",
    "    if not eval[i][1:].isdigit(): eval[i]='+1000'\n",
    "    eval[i]=int(eval[i])\n",
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "eval=eval.astype('int')\n",
    "eval=np.array(eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval=torch.tensor(eval).float()\n",
    "extras=torch.tensor(extras).float()\n",
    "positions=torch.tensor(positions).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessMovePredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChessMovePredictor, self).__init__()\n",
    "        \n",
    "        \n",
    "        # Layer 2: Conv2D\n",
    "        self.conv1 = nn.Conv2d(in_channels=6, out_channels=64, kernel_size=(8, 8), padding=\"same\")\n",
    "        self.bn1 = nn.BatchNorm2d(64, momentum=0.99, eps=1e-05)\n",
    "        \n",
    "        # Layer 3: Conv2D\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=(8, 8), padding=\"same\")\n",
    "        self.bn2 = nn.BatchNorm2d(64, momentum=0.99, eps=1e-05)\n",
    "        \n",
    "        # Layer 4: Flatten\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Layer 5: Input Layer for the second input\n",
    "        # self.input2_layer = nn.Linear(6)\n",
    "        \n",
    "        # # Layer 6: Concatenate\n",
    "        # self.concat = nn.cat()\n",
    "        \n",
    "        # Layer 7-11: Dense Layers\n",
    "        self.dense1 = nn.Linear(4101, 1024)\n",
    "        self.dense2 = nn.Linear(1024, 512)\n",
    "        self.dense3 = nn.Linear(512, 256)\n",
    "        self.dense4 = nn.Linear(256, 256)\n",
    "        self.output_layer = nn.Linear(256, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        # Forward pass through Layer 1-4 for the first input\n",
    "        x1 = self.conv1(x1)\n",
    "        x1 = self.bn1(x1)\n",
    "        x1 = self.conv2(x1)\n",
    "        x1 = self.bn2(x1)\n",
    "        x1 = self.flatten(x1)\n",
    "        \n",
    "        # # Forward pass through Layer 5 for the second input\n",
    "        # x2 = self.input2_layer(x2)\n",
    "        \n",
    "        # Forward pass through Layer 6 (Concatenate)\n",
    "        x = torch.cat((x1, x2),1)\n",
    "        \n",
    "        # Forward pass through Layer 7-11 (Dense Layers)\n",
    "        x = self.relu(self.dense1(x))\n",
    "        x = self.relu(self.dense2(x))\n",
    "        x = self.relu(self.dense3(x))\n",
    "        x = self.relu(self.dense4(x))\n",
    "        output = self.output_layer(x)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Instantiate the model\n",
    "model = ChessMovePredictor()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Number of Trainable Parameters:\", total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_history=[]\n",
    "mse_loss = nn.MSELoss()\n",
    "for i in range (100):\n",
    "    eval_sample=eval[:5000]\n",
    "    positions_sample=positions[:5000]\n",
    "    extras_sample=extras[:5000]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    pred=model(positions_sample,extras_sample)\n",
    "    loss=mse_loss(pred,eval_sample)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_history.append(loss)\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "scores= pd.Series([i.item() for i in loss_history], name=\"scores_Actor\")\n",
    "scores.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "_ = scores.plot(ax=ax, label=\"scores_Actor\")\n",
    "_ = (scores.rolling(window=100)\n",
    "           .mean()\n",
    "           .rename(\"Rolling Average\")\n",
    "           .plot(ax=ax))\n",
    "ax.legend()\n",
    "_ = ax.set_xlabel(\"Episode Number\")\n",
    "_ = ax.set_ylabel(\"scores_Actor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval=np.stack(eval)\n",
    "extras=np.stack(extras)\n",
    "positions=np.stack(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 6, 8, 8)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 6, 8, 64)     32832       ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 6, 8, 64)    256         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 6, 8, 64)     262208      ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 6, 8, 64)    256         ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)            (None, 3072)         0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 3077)         0           ['flatten_4[0][0]',              \n",
      "                                                                  'input_10[0][0]']               \n",
      "                                                                                                  \n",
      " dense_14 (Dense)               (None, 1024)         3151872     ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_15 (Dense)               (None, 1)            1025        ['dense_14[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,448,449\n",
      "Trainable params: 3,448,193\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "input1 = tf.keras.layers.Input(shape=(6,8,8))\n",
    "# shape1 = tf.keras.layers.Reshape(target_shape=(8, 8, 6))(input1)\n",
    "conv1 = tf.keras.layers.Conv2D(kernel_size=(8,8), padding=\"same\", activation=\"relu\", filters=64, input_shape=(8,8,1))(input1)\n",
    "bn1 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-05)(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(kernel_size=(8,8), padding=\"same\", activation=\"relu\", filters=64, input_shape=(8,8,1))(bn1)\n",
    "bn2 = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=1e-05)(conv2)\n",
    "flatten1 = tf.keras.layers.Flatten()(bn2)\n",
    "input2 = tf.keras.layers.Input(shape=(5,))\n",
    "\n",
    "conc = tf.keras.layers.concatenate([flatten1,input2])\n",
    "\n",
    "Denselayer1 = tf.keras.layers.Dense(1024, activation='relu')(conc)\n",
    "# Denselayer2 = tf.keras.layers.Dense(512, activation='relu')(Denselayer1)\n",
    "# Denselayer3 = tf.keras.layers.Dense(256, activation='relu')(Denselayer2)\n",
    "# Denselayer4 = tf.keras.layers.Dense(256, activation='relu')(Denselayer3)\n",
    "Output = tf.keras.layers.Dense(1, activation='linear')(Denselayer1)\n",
    "\n",
    "\n",
    "\n",
    "data_model = tf.keras.models.Model(inputs=[input1, input2], outputs=Output)\n",
    "\n",
    "# predictions = data_model([(inputboard[:1]), (inputmeta[:1])]).numpy\n",
    "\n",
    "metric =[tf.keras.metrics.MeanAbsoluteError()]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Removing the Clipnorm of clipnorm=1 may make training faster\n",
    "#opt = tf.keras.optimizers.Adam(clipnorm=1)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "los = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "data_model.compile(optimizer=opt, \n",
    "                   loss=los,\n",
    "                   metrics=metric)\n",
    "data_model.summary()\n",
    "# data_model.fit([inputboard, inputmeta], data_labels, epochs=1000, batch_size=8192, shuffle=True)\n",
    "\n",
    "# data_model.save(\"engine01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 22s 4s/step - loss: 370555.2812 - mean_absolute_error: 284.5161 - val_loss: 143654.9375 - val_mean_absolute_error: 218.9357\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 23s 4s/step - loss: 358714.2188 - mean_absolute_error: 277.3796 - val_loss: 143387.9688 - val_mean_absolute_error: 218.6862\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 26s 3s/step - loss: 350155.2812 - mean_absolute_error: 297.1836 - val_loss: 143261.3438 - val_mean_absolute_error: 218.7084\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 25s 4s/step - loss: 342262.1875 - mean_absolute_error: 302.3872 - val_loss: 143310.3906 - val_mean_absolute_error: 218.8879\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 25s 3s/step - loss: 329251.9375 - mean_absolute_error: 276.5130 - val_loss: 143185.9219 - val_mean_absolute_error: 218.8744\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 24s 4s/step - loss: 316711.3125 - mean_absolute_error: 260.1830 - val_loss: 142620.9844 - val_mean_absolute_error: 218.5408\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 23s 3s/step - loss: 299082.6875 - mean_absolute_error: 258.7581 - val_loss: 141941.2344 - val_mean_absolute_error: 218.1741\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 25s 4s/step - loss: 281266.9375 - mean_absolute_error: 260.8361 - val_loss: 141378.5781 - val_mean_absolute_error: 217.9559\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 27s 4s/step - loss: 261033.4688 - mean_absolute_error: 246.1155 - val_loss: 140825.3438 - val_mean_absolute_error: 217.8155\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 22s 3s/step - loss: 240036.3281 - mean_absolute_error: 233.0539 - val_loss: 140174.1719 - val_mean_absolute_error: 217.7507\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 20s 3s/step - loss: 220725.7656 - mean_absolute_error: 235.8198 - val_loss: 139415.9375 - val_mean_absolute_error: 217.8322\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 21s 3s/step - loss: 201461.9531 - mean_absolute_error: 232.4350 - val_loss: 138844.0938 - val_mean_absolute_error: 217.9453\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 20s 3s/step - loss: 185851.7344 - mean_absolute_error: 221.4367 - val_loss: 138643.5781 - val_mean_absolute_error: 217.9835\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 20s 3s/step - loss: 167166.3906 - mean_absolute_error: 214.0259 - val_loss: 138523.3594 - val_mean_absolute_error: 218.0309\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 20s 3s/step - loss: 152974.8594 - mean_absolute_error: 205.2256 - val_loss: 138277.3438 - val_mean_absolute_error: 218.1406\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 22s 3s/step - loss: 140896.7344 - mean_absolute_error: 194.9387 - val_loss: 137927.5938 - val_mean_absolute_error: 218.2462\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 26s 4s/step - loss: 130113.6719 - mean_absolute_error: 203.1935 - val_loss: 137866.4062 - val_mean_absolute_error: 218.3027\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 22s 4s/step - loss: 119198.4766 - mean_absolute_error: 190.5766 - val_loss: 137954.3438 - val_mean_absolute_error: 218.3475\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 24s 4s/step - loss: 111596.3516 - mean_absolute_error: 176.2571 - val_loss: 137597.4688 - val_mean_absolute_error: 218.4194\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 23s 3s/step - loss: 105810.5234 - mean_absolute_error: 188.2327 - val_loss: 137298.2500 - val_mean_absolute_error: 218.5146\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 21s 3s/step - loss: 98224.8438 - mean_absolute_error: 176.5114 - val_loss: 136816.0156 - val_mean_absolute_error: 218.7448\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 21s 3s/step - loss: 92139.6797 - mean_absolute_error: 169.2458 - val_loss: 136196.0625 - val_mean_absolute_error: 219.1442\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 22s 4s/step - loss: 90453.3359 - mean_absolute_error: 178.9558 - val_loss: 136052.8906 - val_mean_absolute_error: 219.2529\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 24s 4s/step - loss: 84309.0078 - mean_absolute_error: 166.7245 - val_loss: 136199.3281 - val_mean_absolute_error: 219.1372\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jtm\\Desktop\\summer projects\\chess RL\\predicting_evaluation.ipynb Cell 18\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jtm/Desktop/summer%20projects/chess%20RL/predicting_evaluation.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data_model\u001b[39m.\u001b[39;49mfit([positions[:\u001b[39m9500\u001b[39;49m], extras[:\u001b[39m9500\u001b[39;49m]], \u001b[39meval\u001b[39;49m[:\u001b[39m9500\u001b[39;49m], epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m([positions[\u001b[39m9500\u001b[39;49m:], extras[\u001b[39m9500\u001b[39;49m:]], \u001b[39meval\u001b[39;49m[\u001b[39m9500\u001b[39;49m:]) ,batch_size\u001b[39m=\u001b[39;49m\u001b[39m8192\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\jtm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jtm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1651\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\jtm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\jtm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\jtm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\jtm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    135\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\jtm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1746\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\jtm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    379\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    380\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    381\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    382\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    383\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    384\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\jtm\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_model.fit([positions[:9500], extras[:9500]], eval[:9500], epochs=100, validation_data=([positions[9500:], extras[9500:]], eval[9500:]) ,batch_size=8192, shuffle=True)\n",
    "\n",
    "# data_model.save(\"engine01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=data_model.predict([positions[100:200],extras[100:200]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100,), dtype=float32, numpy=\n",
       "array([150.2159 , 151.89499, 150.34349, 150.99942, 150.26477, 151.86908,\n",
       "       150.21   , 151.76602, 150.87686, 150.84691, 151.0691 , 150.75969,\n",
       "       150.67967, 151.22668, 150.39635, 150.66708, 152.01247, 150.26784,\n",
       "       152.16908, 150.5117 , 151.11232, 151.14258, 150.21219, 151.04903,\n",
       "       150.86034, 151.41896, 150.81696, 150.25232, 151.34113, 151.40695,\n",
       "       150.73305, 150.8349 , 150.70406, 150.40224, 151.29892, 150.31676,\n",
       "       151.3078 , 150.2555 , 151.32483, 150.96211, 152.69647, 150.23701,\n",
       "       151.84142, 150.56471, 150.89053, 150.43225, 151.31436, 150.41504,\n",
       "       151.61224, 150.24232, 151.46129, 150.22014, 152.73276, 150.28444,\n",
       "       152.67119, 150.54617, 150.89508, 150.37766, 151.01553, 150.66339,\n",
       "       150.87843, 150.2369 , 151.521  , 150.30655, 151.17404, 150.8422 ,\n",
       "       150.63673, 150.61893, 151.35849, 150.4205 , 155.23238, 150.998  ,\n",
       "       152.11047, 150.2251 , 151.89786, 152.86531, 151.59998, 150.21   ,\n",
       "       151.89496, 151.78406, 150.33203, 151.91403, 150.82542, 150.21   ,\n",
       "       152.817  , 150.38945, 151.45258, 150.32889, 151.06471, 151.22627,\n",
       "       150.79692, 150.87982, 150.42255, 151.21846, 150.21   , 151.94188,\n",
       "       150.21   , 153.00172, 150.34969, 153.34967], dtype=float32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.losses.mae(eval[100:200],pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
